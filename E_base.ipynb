{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 5,
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from scipy import misc\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "model_dir = os.getcwd() + '/Models/'\n",
    "content_dir = './content/' \n",
    "style_dir =  './50styles/'\n",
    "\n",
    "\n",
    "#vgg definition that conveniently let's you grab the outputs from any layer\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, pool='max'):\n",
    "        super(VGG, self).__init__()\n",
    "        #vgg modules\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        if pool == 'max':\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pool == 'avg':\n",
    "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "    def forward(self, x, out_keys):\n",
    "        out = {}\n",
    "        out['r11'] = F.relu(self.conv1_1(x))\n",
    "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
    "        out['p1'] = self.pool1(out['r12'])\n",
    "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
    "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
    "        out['p2'] = self.pool2(out['r22'])\n",
    "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
    "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
    "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
    "        out['r34'] = F.relu(self.conv3_4(out['r33']))\n",
    "        out['p3'] = self.pool3(out['r34'])\n",
    "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
    "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
    "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
    "        out['r44'] = F.relu(self.conv4_4(out['r43']))\n",
    "        out['p4'] = self.pool4(out['r44'])\n",
    "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
    "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
    "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
    "        out['r54'] = F.relu(self.conv5_4(out['r53']))\n",
    "        out['p5'] = self.pool5(out['r54'])\n",
    "        return [out[key] for key in out_keys]\n",
    "    \n",
    "    \n",
    "    \n",
<<<<<<< HEAD
    "# a function generate corvariant matrix and means with  input feature map\n",
=======
    "\n",
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
    "class Cov_Mean(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b,c,h,w = input.size()\n",
    "        F = input.view(b, c, h*w)\n",
    "        mean_ = F.mean( dim=2, keepdim=True).detach()\n",
    "        mean = torch.cat(h*w*[mean_], 2)\n",
    "        F = F-mean.detach()\n",
    "        G = torch.bmm(F, F.transpose(1,2)) \n",
    "        G.div_(h*w)\n",
    "        return G.squeeze(0).data, mean_.squeeze().data \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# pre and post processing for images\n",
    "img_size = 512 \n",
    "prep = transforms.Compose([transforms.Scale(img_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR\n",
    "                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x.mul_(255)),\n",
    "                          ])\n",
    "postpa = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n",
    "                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], #add imagenet mean\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB\n",
    "                           ])\n",
    "postpb = transforms.Compose([transforms.ToPILImage()])\n",
    "def postp(tensor): # to clip results in the range [0,1]\n",
    "    t = postpa(tensor)\n",
    "    t[t>1] = 1    \n",
    "    t[t<0] = 0\n",
    "    img = postpb(t)\n",
    "    return img\n",
    "\n",
    "#get network\n",
    "vgg = VGG()\n",
    "vgg.load_state_dict(torch.load(model_dir + 'vgg_conv.pth'))\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "if torch.cuda.is_available():\n",
    "    vgg.cuda()\n",
    "\n",
<<<<<<< HEAD
    "    \n",
    "references=[]\n",
    "Reference_dir = './content/'\n",
    "references = glob.glob(Reference_dir+\"*.jpg\")  # generate a list of reference images                    \n",
=======
    "references=[]\n",
    "Reference_dir = './content/'\n",
    "references = glob.glob(Reference_dir+\"*.jpg\")                      \n",
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
    "\n",
    "Total_Covs=[0,0,0,0,0]\n",
    "style_layers = ['r11','r21','r31','r41', 'r51'] \n",
    "\n",
    "for sample in references:    \n",
    "\n",
    "    img_torch = prep(Image.open(sample)) \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        img_torch = Variable(img_torch.unsqueeze(0).cuda()) \n",
    "    else:\n",
    "        img_torch = Variable(img_torch.unsqueeze(0))\n",
    "        sample\n",
<<<<<<< HEAD
    "    Covs_Means = [Cov_Mean()(A) for A in vgg(img_torch, style_layers[:])] # generate corvariant matrix and means for each layer\n",
    "    Total_Covs= [x+y[0] for x,y in zip(Total_Covs,Covs_Means)] # summation of corvariant matrix of each layer over references\n",
=======
    "    Covs_Means = [Cov_Mean()(A) for A in vgg(img_torch, style_layers[:])]\n",
    "    Total_Covs= [x+y[0] for x,y in zip(Total_Covs,Covs_Means)] \n",
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an average over references\n",
    "\n",
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
    "AVG_Covs = [x/len(references) for x in Total_Covs]\n",
    "\n",
    "def PCA(A):\n",
    "        U,S,V = torch.svd(A)\n",
    "        return U,S,V \n",
<<<<<<< HEAD
    "# make a decomposition of each layer    \n",
=======
    "    \n",
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
    "PCA_basis = [PCA(data) for data in AVG_Covs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 7,
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 344010 style6_content344010_weight11.0_weight100.0_iteration799.png\n",
      "6 344010 style6_content344010_weight11.0_weight150.0_iteration799.png\n",
      "10 141012 style10_content141012_weight11.0_weight0.1_iteration699.png\n",
      "10 141012 style10_content141012_weight11.0_weight0.5_iteration799.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ks = [ 32,48,128,256,256]\n",
    "\n",
    "file1 = open('sample.txt', 'r') \n",
    "file2= open('EValue%s.txt'%Ks, 'w')\n",
    "columns = [\"style\", \"content\",\"weight\",\"E1\",\"E2\",\"E3\",\"E4\",\"E5\",\"\\n\"]\n",
    "name = '\\t'.join(columns) \n",
    "file2.write(name)\n",
    "\n",
    "\n",
    "for line in file1.readlines()[:]:\n",
    "    \n",
    "    filename  = line[:-1] \n",
    "    sp =line[:].split('_')\n",
    "    style =int(sp[0][5:]) \n",
    "    content = int(sp[1][7:])\n",
    "    print(style,content, filename)\n",
    " \n",
    "    source_dir = './sample/'\n",
    "    img_dirs = [style_dir, content_dir, source_dir]\n",
    "    img_names = ['styles - %s.jpg'%style, '%s.jpg'%content, filename]\n",
    "    imgs = [Image.open(img_dirs[i] + name) for i,name in enumerate(img_names)]\n",
    "    imgs_torch = [prep(img) for img in imgs]\n",
    "    if torch.cuda.is_available():\n",
    "        imgs_torch = [Variable(img.unsqueeze(0).cuda()) for img in imgs_torch]\n",
    "    else:\n",
    "        imgs_torch = [Variable(img.unsqueeze(0)) for img in imgs_torch]\n",
    "    style_image, content_image, syn_image= imgs_torch\n",
    "\n",
    "\n",
    "    style_layers = ['r11','r21','r31','r41', 'r51'] \n",
    "    content_layers = ['r42']  \n",
    "\n",
    "    style_targets = [Cov_Mean()(A) for A in vgg(style_image, style_layers[:])]\n",
    "    syn_results = [Cov_Mean()(A) for A in vgg(syn_image, style_layers[:])]\n",
    "\n",
    "\n",
    "    def PCA_Proj(A,P,k):\n",
    "        return torch.mm(torch.mm(P[0][:,:k].t(),A[0]),P[2][:,:k]), torch.mm( A[1].unsqueeze(0), P[0][:,:k] ) \n",
    "    \n",
    "    PCA_targets = [PCA_Proj(data,P ,k) for data,P,k in zip(style_targets,PCA_basis,Ks)]\n",
    "    PCA_syn_results = [PCA_Proj(data,P ,k) for data,P,k in zip(syn_results,PCA_basis,Ks)]     \n",
    "  \n",
    "    def Det(A,B):\n",
    "        _,S,_ = torch.svd(A)\n",
    "        _,S1,_ = torch.svd(B)\n",
    "        temp =torch.log(S1/S)\n",
    "        u=0\n",
    "        for a in temp:\n",
    "            u +=a\n",
    "        return u\n",
    "    \n",
    "    LogDet_AoverB = [ Det(syn[0],tar[0]) for syn,tar,k in zip(PCA_syn_results,PCA_targets,Ks)]\n",
    "\n",
    "    KLs = []\n",
    "\n",
    "    KL_parts  = [ (torch.trace(torch.mm( y[0].inverse(), x[0])), torch.mm( torch.mm((y[1] -x[1]),  y[0].inverse()), (y[1]-x[1]).t() ).squeeze()[0] ,-k, logD) for x,y,logD, k in zip(PCA_syn_results,PCA_targets,LogDet_AoverB,Ks)]\n",
    "\n",
    "    KLs.append(np.sum(x) for x in KL_parts )  # np.sum(x) gives the 2 KL divergence\n",
    "    KL_array = np.array(KLs)\n",
    "    Es = [ str(-np.log(x)+ np.log(2)) for x in KLs[0]] # E value is -log(KL)\n",
    "    new = sp[:3]+Es +[\"\\n\"]  \n",
    " \n",
    "    name = '\\t'.join(new) \n",
    "    file2.write(name)\n",
    "file1.close()\n",
    "file2.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 13,
>>>>>>> cd664a884a3ce811e61753ddd0160b67f19e0b22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 344010\n",
      "6 344010\n",
      "10 141012\n",
      "10 141012\n"
     ]
    }
   ],
   "source": [
    "file1 = open('sample.txt', 'r') \n",
    "\n",
    "for line in file1.readlines()[:]:\n",
    "    sp =line[:].split('_')\n",
    "    style =int(sp[0][5:]) \n",
    "\n",
    "    content = int(sp[1][7:])\n",
    "    print(style,content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
